{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalWant/Apache-kafka/blob/main/kafka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smptt_WAUczd"
      },
      "source": [
        "setup Kafka:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3B5ghGWZPiV"
      },
      "source": [
        "- Kafka (Brokers: 127.0.0.1:9092)\n",
        "- Zookeeper (Node: 127.0.0.1:2181)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUj0878jPyz7"
      },
      "outputs": [],
      "source": [
        "!curl -sSOL https://dlcdn.apache.org/kafka/3.1.0/kafka_2.13-3.1.0.tgz\n",
        "!tar -xzf kafka_2.13-3.1.0.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDJYdAp3WT4L"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJc6DH6VBFPQ"
      },
      "source": [
        "Using the default configurations (provided by Apache Kafka) for spinning up the instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nKBoWTgYqnV"
      },
      "outputs": [],
      "source": [
        "!./kafka_2.13-3.1.0/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-3.1.0/config/zookeeper.properties\n",
        "!./kafka_2.13-3.1.0/bin/kafka-server-start.sh -daemon ./kafka_2.13-3.1.0/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN9RnVcUZz3O"
      },
      "outputs": [],
      "source": [
        "!ps -ef | grep kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02WiLZxYcoZh"
      },
      "outputs": [],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic susy-train\n",
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 2 --topic susy-test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4z0ut70PLVC"
      },
      "outputs": [],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic susy-train\n",
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic susy-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUQOhcV9QEAo"
      },
      "outputs": [],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --list --bootstrap-server 127.0.0.1:9092\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R5nRfsfFa7CA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e8f72f-b1ee-4ff1-da2d-d8f293c20db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">new\n",
            ">thread\n",
            ">images\n",
            ">soon to follow\n",
            ">"
          ]
        }
      ],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-console-producer.sh  --broker-list 127.0.0.1:9092  --topic susy-train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m1OhgpJvnoUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1432427-609f-4a9a-e33f-bcf85c8aae62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new\n",
            "thread\n",
            "images\n",
            "soon to follow\n",
            "Processed a total of 4 messages\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-console-consumer.sh --topic susy-train --bootstrap-server localhost:9092 --from-beginning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHsyKh9jqgm6"
      },
      "source": [
        "Using Python to interact with kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q05T2B5hr8rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adb4dd7-61b4-4d8a-fb6c-1f4c0980b9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting confluent-kafka\n",
            "  Downloading confluent_kafka-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: confluent-kafka\n",
            "Successfully installed confluent-kafka-1.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install confluent-kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P9eTgkTpHQ0"
      },
      "outputs": [],
      "source": [
        "import asyncio \n",
        "\n",
        "from confluent_kafka import Consumer, Producer \n",
        "from confluent_kafka.admin import AdminClient, NewTopic \n",
        "\n",
        "BROKER_URL= \"PLAINTEXT://localhost:9092\" \n",
        "TOPIC_NAME= \"susy-train\" \n",
        "\n",
        "async def produce(topic_name): \n",
        "  \"\"\" Produce data into kafka topic\"\"\" \n",
        "  p= Producer({\"bootstrap.servers\":BROKER_URL})\n",
        "  curr_iteration=0 \n",
        "  \n",
        "  while True: \n",
        "    p.produce(TOPIC_NAME, f\"Message:{curr_iteration}\")\n",
        "    curr_iteration+=1 \n",
        "\n",
        "\n",
        "    await asyncio.sleep(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def consume(topic_name): \n",
        "  \"\"\" consume data from kafka topic\"\"\" \n",
        "  c= Consumer({\"bootstrap.servers\":BROKER_URL, \"group.id\":\"First-Python_consumer\"})\n",
        "  c.subscribe([TOPIC_NAME]) \n",
        "\n",
        "  while True:\n",
        "    message= c.poll(1.0)\n",
        "    if message is None :\n",
        "      print(\"No message received\") \n",
        "    \n",
        "    elif message.error() is not None: \n",
        "      print(f\"Message had an error{ message.error()}\")\n",
        "    else: \n",
        "      print(f\"Key: {message.key()}, Value:{message.value()}\")\n",
        "\n",
        "    await asyncio.sleep(1) \n",
        "\n",
        "\n",
        "async def produce_consume():\n",
        "  \"\"\" Runs the producer and consumer task\"\"\"\n",
        "  t1= asyncio.create_task(produce(TOPIC_NAME)) \n",
        "  t2= asyncio.create_task(consume(TOPIC_NAME))\n",
        "\n",
        "  await t1\n",
        "  await t2\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "  client= AdminClient({\"bootstrap.servers\":BROKER_URL})\n",
        "  topic= NewTopic(TOPIC_NAME, num_partitions=1, replication_factor=1)\n",
        "\n",
        "  client.create_topics([topic])\n",
        "\n",
        "  try: \n",
        "    asyncio.run(produce_consume()) \n",
        "  \n",
        "  except: \n",
        "    print(\"Shutting Down\") \n",
        "  \n",
        "  finally: \n",
        "    client.delete_topics([topic]) \n",
        "    pass \n",
        "\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr9sdhcJvLiU"
      },
      "outputs": [],
      "source": [
        "#!tail -f /var/log/journal/confluent-kafka.service.log    ---Kafka logs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Topic "
      ],
      "metadata": {
        "id": "1quV8ti3ROYp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79z0LEdYwvg_"
      },
      "outputs": [],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic kafka-arch \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --alter --topic kafka-arch --partitions 3 --bootstrap-server 127.0.0.1:9092"
      ],
      "metadata": {
        "id": "t_gh_et9Sw23"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls kafka_2.13-3.1.0/bin"
      ],
      "metadata": {
        "id": "OT_KqujPU_e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls kafka_2.13-3.1.0/config"
      ],
      "metadata": {
        "id": "4pPC3fdCVFv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls kafka_2.13-3.1.0/libs"
      ],
      "metadata": {
        "id": "t9FDPcLOWZ_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls kafka_2.13-3.1.0/"
      ],
      "metadata": {
        "id": "NOQcpw1NWhLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /usr"
      ],
      "metadata": {
        "id": "fQQRbqg3Wtrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! find / -name kafka-arch\n",
        "\n"
      ],
      "metadata": {
        "id": "1whiDHH_YMb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio \n",
        "\n",
        "from confluent_kafka import Consumer, Producer \n",
        "from confluent_kafka.admin import AdminClient, NewTopic \n",
        "\n",
        "BROKER_URL= \"PLAINTEXT://localhost:9092\" \n",
        "TOPIC_NAME=\"sample2\" \n",
        "\n",
        "async def produce(topic_name): \n",
        "  \"\"\" Produce data into kafka topic\"\"\" \n",
        "  p= Producer({\"bootstrap.servers\":BROKER_URL})\n",
        "  curr_iteration=0 \n",
        "  \n",
        "  while True: \n",
        "    p.produce(TOPIC_NAME, f\"Message:{curr_iteration}\")\n",
        "    curr_iteration+=1 \n",
        "\n",
        "\n",
        "    await asyncio.sleep(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def consume(topic_name): \n",
        "  \"\"\" consume data from kafka topic\"\"\" \n",
        "  c= Consumer({\"bootstrap.servers\":BROKER_URL, \"group.id\":\"First-Python_consumer\"})\n",
        "  c.subscribe([TOPIC_NAME]) \n",
        "\n",
        "  while True:\n",
        "    message= c.poll(1.0)\n",
        "    if message is None :\n",
        "      print(\"No message received\") \n",
        "    \n",
        "    elif message.error() is not None: \n",
        "      print(f\"Message had an error{ message.error()}\")\n",
        "    else: \n",
        "      print(f\"Key: {message.key()}, Value:{message.value()}\")\n",
        "\n",
        "    await asyncio.sleep(1) \n",
        "\n",
        "\n",
        "async def produce_consume(topic_name):\n",
        "  \"\"\" Runs the producer and consumer task\"\"\"\n",
        "  t1= asyncio.create_task(produce(topic_name)) \n",
        "  t2= asyncio.create_task(consume(topic_name))\n",
        "\n",
        "  await t1\n",
        "  await t2\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------\n",
        "def topic_exists(client, topic_name): \n",
        "  \"\"\"checks if the given topic exists\"\"\"\n",
        "  topic_metadata= client.list_topics(timeout=5) \n",
        "  return topic_metadata.topics.get(topic_name) is not None \n",
        "\n",
        "\n",
        "\n",
        "def create_topic(client, topic_name): \n",
        "  \"\"\" create the topic with the given topic name\"\"\" \n",
        "  futures= client.create_topics(\n",
        "      [\n",
        "       NewTopic(\n",
        "           topic= topic_name, \n",
        "           num_partitions=5, \n",
        "           replication_factor=1,\n",
        "           config={\n",
        "               \"cleanup.policy\": \"compact\",\n",
        "               \"compression.type\": \"lz4\",\n",
        "               \"delete.retention.ms\": 100,\n",
        "               \"file.delete.delay.ms\":100,\n",
        "\n",
        "           }\n",
        "       )\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  for _, future in futures.items():\n",
        "    try: \n",
        "      future.result()\n",
        "      print(\"Topic Created\") \n",
        "    except Exception as e: \n",
        "      print(f\"failed to created topic {topic_name}:{e}\")\n",
        "      raise \n",
        "\n",
        "\n",
        "\n",
        "def main(): \n",
        "  \"\"\" check fro topic and creates the topic if it does not exist\"\"\" \n",
        "\n",
        "  client = AdminClient({\"bootstrap.servers\":BROKER_URL}) \n",
        "\n",
        "  # TODO: Decide on a topic name \n",
        "  topic_name= \"sample3\" \n",
        "  exists= topic_exists(client, topic_name) \n",
        "\n",
        "  print(f\"Topic{topic_name} exists: {exists}\")\n",
        "\n",
        "  if exists is False: \n",
        "    create_topic(client, topic_name) \n",
        "  \n",
        "  try: \n",
        "    asyncio.run(produce_consume(topic_name))\n",
        "\n",
        "  except KeyboardInterrupt as e: \n",
        "    print(\"shutting Down\") \n",
        "\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "NoKUE-KGY8a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@dataclass \n",
        "class Purchase: \n",
        "  username: str= field(default_factory= faker.user_name) \n",
        "  currency: str= field(default_factory= faker.curreny_code) \n",
        "  amount: int = field(default_factory= lambda: random.randInt(100, 200000)) \n",
        "\n",
        "  def serialize(self): \n",
        "    return json.dumps(asdict(self))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def produce (topic_name): \n",
        "  \"\"\" produces data into kafka topic\"\"\" \n",
        "  p= Producer({\"bootstrap.servers\": BROKER_URL}) \n",
        "\n",
        "  start_time= datetime.utcnow() \n",
        "  curr_iteration=0 \n",
        "\n",
        "  while True: \n",
        "    p.produce(topic_name, Purchase().serialize()) \n",
        "    \n",
        "\n",
        "    #p.flush()     for making it synchronous \n",
        "    if curr_iteration % 1000==0: \n",
        "      elapsed= (datetime.utcnow()-start_time).seconds \n",
        "      print(f\"Messages  : {curr_iteration} | Total elapsed seconds: {elapsed}\") \n",
        "    \n",
        "    curr_iteration+=1 \n",
        "\n",
        "\n",
        "\n",
        "def main(): \n",
        "  \"\"\" checks for topic and creates the topic if it does not exist\"\"\" \n",
        "\n",
        "  create_topic(TOPIC_NAME) \n",
        "  try: \n",
        "    asyncio.run(produce_consume(TOPIC_NAME)) \n",
        "  \n",
        "  except KeyboardInterrupt as e: \n",
        "    print(\"shutting Down\") \n",
        "\n",
        "\n",
        "async def produce_consume(topic_name): \n",
        "  \"\"\" Runs the producer and consumer tasks\"\"\" \n",
        "  producer= asyncio.create_task(produce(topic_name)) \n",
        "  await producer  \n",
        "\n",
        "\n",
        "def create_topic(client): \n",
        "  \"\"\" creates the toic with the given topic name\"\"\" \n",
        "  client= AdminClient({\"bootstrap.servers\": BROKER_URL}) \n",
        "  futures= client.create_topics(\n",
        "      [NewTopic(topic= TOPIC_NAME,num_partitions=5, replication_factor=1)]\n",
        "\n",
        "  )\n",
        "\n",
        "  for _, future in futures.items(): \n",
        "    try: \n",
        "      future.result() \n",
        "    \n",
        "    except Exception as e: \n",
        "      pass \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0Ux4ZvVC2VAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "kafka.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdNv3oyr+4vGWAEa/YGlkO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}